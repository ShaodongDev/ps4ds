


import matplotlib
import matplotlib.pyplot as plt
import numpy as np
from os import listdir
import seaborn as sns
from scipy import stats
from numpy import linalg as LA
from sklearn.linear_model import LinearRegression,Ridge,RidgeCV,Lasso,LassoCV
from numpy.random import default_rng
# import cartopy
# import cartopy.crs as ccrs
# import cartopy.feature as cfeature

font_size = 30
font_size_ticks = 30

np.set_printoptions(precision=5)

def process_name(x):
    x = x[14:]
    x = x[:-7]
    x = x.translate(str.maketrans('','','_1234567890'))
    return x[2:] + ", " + x[:2]

def state(x):
    x = x[14:]
    return x[:2]

str_path = "../data/weather/"

file_name_temperatures_2015 = str_path + "temperatures_2015.npy"
file_name_temperatures_2016 = str_path + "temperatures_2016.npy"

data_matrix_2015 = np.load(file_name_temperatures_2015)
data_matrix_2016 = np.load(file_name_temperatures_2016)

file_name_list = listdir(str_path + "hourly/2015/")
file_name_list.sort()

latitudes = []
longitudes = []
for ind,name in enumerate(file_name_list):
    print(ind)
    print(name)
    if name[0] != '.':
        data_aux = np.loadtxt(str_path + "hourly/2015/" + name, usecols=range(14))
        print("longitude: " + str(data_aux[0,6]))
        print("latitude: " + str(data_aux[0,7]))
        longitudes.append(data_aux[0,6])
        latitudes.append(data_aux[0,7])


def remove_faulty_measurements(data,verbose):
    min_val = -100 # We assume temperatures cannot be lower than -100
    for ind in range(len(data)):
        median = np.median(data[data > min_val])
        if data[ind] < min_val:
            if verbose:
                print(str(ind) + ": " + str(data[ind]))
            aux_ind = ind-1
            while aux_ind > 0:
                if data[aux_ind] > min_val:
                    data[ind] = data[aux_ind]
                    if verbose:
                        print("changed entry " + str(aux_ind) + ": " + str(data[ind]))
                    break
                else:
                    ind -= 1
    return data

verbose = True
for ind in range(data_matrix_2015.shape[1]):
    print(ind)
    data_matrix_2015[:,ind] = remove_faulty_measurements(data_matrix_2015[:,ind],verbose)
    data_matrix_2016[:,ind] = remove_faulty_measurements(data_matrix_2016[:,ind],verbose)


print(data_matrix_2015.shape)
print(data_matrix_2016.shape)

ind_response = 55
print( "Response is " + process_name(str(file_name_list[ind_response+1])))
y_all = data_matrix_2015[:,ind_response]
y_2016 = data_matrix_2016[:,ind_response]
n_2016 = len(y_2016)
longitude_y = longitudes[ind_response]
latitude_y = latitudes[ind_response]

ind_X = np.hstack((np.arange(0,ind_response),np.arange(ind_response+1,data_matrix_2015.shape[1])))
XT_all = data_matrix_2015[:,ind_X]
XT_2016 = data_matrix_2016[:,ind_X]
longitudes_X = np.array(longitudes)[ind_X]
latitudes_X = np.array(latitudes)[ind_X]

d = XT_all.shape[1]

n_test = int(1e3)
n_data = data_matrix_2015.shape[0]
print(n_data)
rng = default_rng(2023)
aux_ind = rng.permutation(n_data)
ind_test = aux_ind[:n_test]
XT_test = XT_all[ind_test,:]
y_test = y_all[ind_test]
ind_train = aux_ind[n_test:]
XT_train = XT_all[ind_train,:]
y_train = y_all[ind_train]
print(ind_X[:5])
print(XT_train.shape)
print(y_train.shape)
n_train = XT_train.shape[0]
print("Number of features",d)
print("Number of training examples",n_train)


n_vals = np.logspace(np.log10(d),np.log10(n_train)).astype(int)
print(n_vals)
n_alphas = 200
n_alpha_lasso = 200
alphas_val = np.logspace(-1, 6, n_alphas)

n_len = len(n_vals)
cov_matrix_eigvals = np.zeros((d,n_len)) 

OLS_coeffs_array = np.zeros((d,n_len)) 
OLS_training_error = np.zeros(n_len)
OLS_test_error = np.zeros(n_len)
OLS_test_error_2016 = np.zeros(n_len)
ridge_coeffs_array = np.zeros((d,n_len)) 
ridge_training_error = np.zeros(n_len)
ridge_test_error = np.zeros(n_len)
ridge_test_error_2016 = np.zeros(n_len)
ridge_alphas = np.zeros(n_len) 
lasso_coeffs_array = np.zeros((d,n_len)) 
lasso_training_error = np.zeros(n_len)
lasso_test_error = np.zeros(n_len)
lasso_test_error_2016 = np.zeros(n_len)
lasso_alphas = np.zeros(n_len) 

for ind_n,n in enumerate(n_vals):
    XT_train_n = XT_train[:n,:]
    y_train_n = y_train[:n]
    cov_matrix = np.cov(XT_train_n.T,ddof=1)
    eigvals_cov_matrix,eigvecs_cov_matrix = np.linalg.eig(cov_matrix)
    cov_matrix_eigvals[:,ind_n] = np.sort(eigvals_cov_matrix)

    OLS_model_n = LinearRegression().fit(XT_train_n, y_train_n)
    OLS_coeffs_array[:,ind_n] = OLS_model_n.coef_
    OLS_training_error[ind_n] = np.sqrt(np.sum((y_train_n - OLS_model_n.predict(XT_train_n))**2) / n )
    #training_error[ind_n] = OLS_model_n.score(XT_train_n, y_train_n)
    OLS_test_error[ind_n] = np.sqrt(np.sum((y_test - OLS_model_n.predict(XT_test))**2) / n_test )
    #test_error[ind_n] = OLS_model_n.score(XT_test, y_test)
    OLS_test_error_2016[ind_n] = np.sqrt(np.sum((y_2016 - OLS_model_n.predict(XT_2016))**2) / n_2016 )
    #test_error_2016[ind_n] = OLS_model_n.score(XT_2016, y_2016)
    
    ridge_model_n = RidgeCV(alphas=alphas_val).fit(XT_train_n, y_train_n)
    ridge_coeffs_array[:,ind_n] = ridge_model_n.coef_
    ridge_training_error[ind_n] = np.sqrt(np.sum((y_train_n - ridge_model_n.predict(XT_train_n))**2) / n )
    ridge_test_error[ind_n] = np.sqrt(np.sum((y_test - ridge_model_n.predict(XT_test))**2) / n_test )
    ridge_test_error_2016[ind_n] = np.sqrt(np.sum((y_2016 - ridge_model_n.predict(XT_2016))**2) / n_2016 )
    ridge_alphas[ind_n] = ridge_model_n.alpha_

    lasso_model_n = LassoCV(n_alphas=n_alpha_lasso,max_iter=100000).fit(XT_train_n, y_train_n)
    lasso_coeffs_array[:,ind_n] = lasso_model_n.coef_
    lasso_training_error[ind_n] = np.sqrt(np.sum((y_train_n - lasso_model_n.predict(XT_train_n))**2) / n )
    lasso_test_error[ind_n] = np.sqrt(np.sum((y_test - lasso_model_n.predict(XT_test))**2) / n_test )
    lasso_test_error_2016[ind_n] = np.sqrt(np.sum((y_2016 - lasso_model_n.predict(XT_2016))**2) / n_2016 )
    lasso_alphas[ind_n] = lasso_model_n.alpha_


xtick_vals = [133,250,500,1000,2000,5000]
sigma_est = OLS_training_error[-1]
theoretical_prediction_train = sigma_est * np.sqrt(1-d/n_vals)
theoretical_prediction_test = sigma_est * np.sqrt(1+d/(n_vals-1))
fig = plt.figure(figsize = (12,9)) 
plt.semilogx(n_vals,OLS_test_error,"o",markersize=10,markerfacecolor='black',markeredgecolor="black",markeredgewidth =2,label="Test error")
plt.semilogx(n_vals,OLS_training_error,"o",markersize=12,markerfacecolor='white',markeredgecolor="black",markeredgewidth =2,label="Training error")
# plt.semilogx(n_vals,OLS_test_error_2016,"o")
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
plt.ylim([-0.15,4.25])
#plt.xlim([1,n_train+10])
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.legend(fontsize=font_size,framealpha=1)
plt.xlabel(r'Number of training data',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Error ($^\circ$C)',fontsize=font_size,labelpad = 15)
plt.savefig('plots/OLS_training_test_error.pdf',bbox_inches="tight")

fig = plt.figure(figsize = (12,9)) 
plt.semilogx(n_vals,OLS_test_error,"o",markersize=12,markerfacecolor='silver',markeredgecolor="silver",markeredgewidth =2)
plt.semilogx(n_vals,OLS_training_error,"o",markersize=12,markerfacecolor='silver',markeredgecolor="silver",markeredgewidth =2)
# plt.semilogx(n_vals,OLS_test_error_2016,"o")
plt.semilogx(n_vals,theoretical_prediction_test,lw=5,ls="solid",color="black",label="Theoretical test error")
plt.semilogx(n_vals,theoretical_prediction_train,lw=4,ls="dashed",color="black",label="Theoretical training error")
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
plt.ylim([-0.15,4.25])
#plt.xlim([1,n_train+10])
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.legend(fontsize=font_size,framealpha=1)
plt.xlabel(r'Number of training data',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Error ($^\circ$C)',fontsize=font_size,labelpad = 15)
plt.savefig('plots/OLS_training_test_error_theory.pdf',bbox_inches="tight")



fig = plt.figure(figsize = (20,10)) 
plt.semilogx(n_vals,OLS_test_error,"o",markersize=10,markerfacecolor='black',markeredgecolor="black",markeredgewidth =2,label="OLS (test)")
plt.semilogx(n_vals,ridge_test_error,"^",markersize=10,markerfacecolor='black',markeredgecolor="black",markeredgewidth =2,label="Ridge (test)")
plt.semilogx(n_vals,lasso_test_error,"d",markersize=10,markerfacecolor='black',markeredgecolor="black",markeredgewidth =2,label="Lasso (test)")
plt.semilogx(n_vals,lasso_training_error,"d",markersize=12,markerfacecolor='white',markeredgecolor="black",markeredgewidth =2,label="Lasso (training)")
plt.semilogx(n_vals,ridge_training_error,"^",markersize=12,markerfacecolor='white',markeredgecolor="black",markeredgewidth =2,label="Ridge (training)")
plt.semilogx(n_vals,OLS_training_error,"o",markersize=12,markerfacecolor='white',markeredgecolor="black",markeredgewidth =2,label="OLS (training)")
# plt.semilogx(n_vals,OLS_test_error_2016,"o")
#plt.semilogx(n_vals,ridge_training_error,"x")
#plt.semilogx(n_vals,ridge_test_error,"x")
#plt.semilogx(n_vals,ridge_test_error_2016,"x")
#plt.semilogx(n_vals,lasso_training_error,"d")
#plt.semilogx(n_vals,lasso_test_error,"d")
# plt.semilogx(n_vals,lasso_test_error_2016,"d")

plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
plt.ylim([-0.15,4.25])
#plt.xlim([1,n_train+10])
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.legend(fontsize=font_size,framealpha=1)
plt.xlabel(r'Number of training data',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Error ($^\circ$C)',fontsize=font_size,labelpad = 15)
plt.savefig('plots/OLS_ridge_lasso_training_test_error.pdf',bbox_inches="tight")

fig = plt.figure(figsize = (9,9)) 
#for ind in range(d):
#    plt.loglog(n_vals,cov_matrix_eigvals[ind,:],'o')
#plt.ylim([1e-3,2e-1])
plt.plot(n_vals,ridge_alphas/n_vals,"o",markersize=10,markerfacecolor='white',markeredgecolor="black",markeredgewidth =2)
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Regularization parameter $\lambda/n$',fontsize=font_size,labelpad = 15)
plt.savefig('plots/ridge_reg_param.pdf',bbox_inches="tight")

fig = plt.figure(figsize = (9,9)) 
#for ind in range(d):
#    plt.loglog(n_vals,cov_matrix_eigvals[ind,:],'o')
#plt.ylim([1e-3,2e-1])
plt.plot(n_vals,2*lasso_alphas,"o",markersize=10,markerfacecolor='white',markeredgecolor="black",markeredgewidth =2)
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Regularization parameter $\lambda/n$',fontsize=font_size,labelpad = 15)
plt.savefig('plots/lasso_reg_param.pdf',bbox_inches="tight")



largest_coeff_ind = np.argsort(OLS_coeffs_array[:,-1])[-1] 
second_largest_coeff_ind = np.argsort(OLS_coeffs_array[:,-1])[-2] 
third_largest_coeff_ind = np.argsort(OLS_coeffs_array[:,-1])[-3] 

fig = plt.figure(figsize = (9,9)) 
for ind_feature in range(d):
    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:
        plt.semilogx(n_vals,OLS_coeffs_array[ind_feature,:],lw=3,color="silver")
plt.semilogx(n_vals,OLS_coeffs_array[largest_coeff_ind,:],lw=3,color="black",label="Bowling Green")
plt.semilogx(n_vals,OLS_coeffs_array[second_largest_coeff_ind,:],lw=3,ls="dashed",color="black",label="Bedford")
plt.semilogx(n_vals,OLS_coeffs_array[third_largest_coeff_ind,:],lw=4,ls="dotted",color="black",label="Elkins")
plt.legend(fontsize=font_size,framealpha=1,loc="lower right")
plt.ylim([-1,1])
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 20)
plt.savefig('plots/OLS_coefficients.pdf',bbox_inches="tight")

fig = plt.figure(figsize = (9,9)) 
for ind_feature in range(d):
    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:
        plt.semilogx(n_vals,ridge_coeffs_array[ind_feature,:],lw=3,color="silver")
plt.semilogx(n_vals,ridge_coeffs_array[largest_coeff_ind,:],lw=3,color="black",label="Bowling Green")
plt.semilogx(n_vals,ridge_coeffs_array[second_largest_coeff_ind,:],lw=3,ls="dashed",color="black",label="Bedford")
plt.semilogx(n_vals,ridge_coeffs_array[third_largest_coeff_ind,:],lw=4,ls="dotted",color="black",label="Elkins")
plt.legend(fontsize=font_size,framealpha=1,loc="lower right")
plt.ylim([-1,1])
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 20)
plt.savefig('plots/ridge_coefficients.pdf',bbox_inches="tight")

fig = plt.figure(figsize = (9,9)) 
for ind_feature in range(d):
    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:
        plt.semilogx(n_vals,lasso_coeffs_array[ind_feature,:],lw=3,color="silver")
plt.semilogx(n_vals,lasso_coeffs_array[largest_coeff_ind,:],lw=3,color="black",label="Bowling Green")
plt.semilogx(n_vals,lasso_coeffs_array[second_largest_coeff_ind,:],lw=3,ls="dashed",color="black",label="Bedford")
plt.semilogx(n_vals,lasso_coeffs_array[third_largest_coeff_ind,:],lw=4,ls="dotted",color="black",label="Elkins")
plt.legend(fontsize=font_size,framealpha=1,loc="lower right")
plt.ylim([-1,1])
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 20)
#plt.ylabel(r'Regularization parameter $\lambda/n$',fontsize=font_size,labelpad = 15)
plt.savefig('plots/lasso_coefficients.pdf',bbox_inches="tight")



coeffs = OLS_coeffs_array[:,-1]
coeff_marker = 40
print("Largest coefficient:",file_name_list[ind_X[largest_coeff_ind]+1] )
print("2nd largest coefficient:",file_name_list[ind_X[second_largest_coeff_ind]+1])
print("3rd largest coefficient:",file_name_list[ind_X[third_largest_coeff_ind]+1])

fig = plt.figure(figsize=(15,6))
ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.LambertConformal())
ax.set_extent([-120, -77.5, 24, 45], ccrs.Geodetic())

ax.coastlines()
ax.plot(longitude_y,latitude_y, '*', markersize=20,color="black",markeredgewidth=2,
        markerfacecolor="white",transform=ccrs.Geodetic(),label='Response')
for ind in range(d):
    if coeffs[ind] > 0:
        ax.plot(longitudes_X[ind],latitudes_X[ind],'o',ms=coeff_marker*coeffs[ind],color="black",markeredgewidth=2,
                 markerfacecolor="white",transform=ccrs.Geodetic())
    else:
        ax.plot(longitudes_X[ind],latitudes_X[ind],'o',ms=-coeff_marker*coeffs[ind],markeredgecolor="black",markeredgewidth=2,
                 markerfacecolor="black",transform=ccrs.Geodetic())
plt.text(longitude_y+1,latitude_y-0.5,"Versailles",transform=ccrs.Geodetic(),fontsize=24)
plt.text(longitude_y-13.5,latitude_y-1,"Bowling Green",transform=ccrs.Geodetic(),fontsize=24)
plt.text(longitude_y-8.25,latitude_y+1.75,"Bedford",transform=ccrs.Geodetic(),fontsize=24)
plt.text(longitude_y+3,latitude_y+2,"Elkins",transform=ccrs.Geodetic(),fontsize=24)
plt.ylabel('Latitude',fontsize=font_size,labelpad=10)
plt.xlabel('Longitude',fontsize=font_size,labelpad=10)
plt.savefig('plots/OLS_coeffs_map.pdf',bbox_inches="tight")


fig = plt.figure(figsize = (9,9)) 
#for ind in range(d):
#    plt.loglog(n_vals,cov_matrix_eigvals[ind,:],'o')
#plt.ylim([1e-3,2e-1])
plt.plot(n_vals,cov_matrix_eigvals[0,:],"o",markersize=10,markerfacecolor='white',markeredgecolor="black",markeredgewidth =2)
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
ax = plt.gca()
ax.set_xscale('log')
ax.set_xticks(xtick_vals)
ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())
plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Smallest eigenvalue',fontsize=font_size,labelpad = 15)
plt.savefig('plots/cov_matrix_smallest_eigenvalue.pdf',bbox_inches="tight")



n = 200
alphas_val_ridge = np.logspace(-1, 6, n_alphas)
ridge_training_error_alpha = np.zeros(n_alphas) 
ridge_test_error_alpha = np.zeros(n_alphas)
ridge_coeffs_array_alpha = np.zeros((d,n_alphas)) 

for ind_alpha,alpha_val in enumerate(alphas_val_ridge):
    XT_train_n = XT_train[:n,:]
    y_train_n = y_train[:n]
    
    ridge_model_alpha = Ridge(alpha=alpha_val).fit(XT_train_n, y_train_n)
    ridge_training_error_alpha[ind_alpha] = np.sqrt(np.sum((y_train_n - ridge_model_alpha.predict(XT_train_n))**2) / n )
    ridge_test_error_alpha[ind_alpha] = np.sqrt(np.sum((y_test - ridge_model_alpha.predict(XT_test))**2) / n_test )
    ridge_coeffs_array_alpha[:,ind_alpha] = ridge_model_alpha.coef_

fig = plt.figure(figsize = (9,9)) 
plt.semilogx(alphas_val,ridge_test_error_alpha,lw=4,color="black",label="Test error")
# plt.semilogx(alphas_val,ridge_test_error_alpha,"o",markersize=10,markerfacecolor='black',markeredgecolor="black",
#             markeredgewidth =2,label="Test error")
# plt.semilogx(alphas_val,ridge_training_error_alpha,"o",markersize=10,markerfacecolor='white',markeredgecolor="black",
#             markeredgewidth =2,label="Training error")
plt.semilogx(alphas_val,ridge_training_error_alpha,ls="dashed",lw=4,color="black",label="Training error")
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
plt.legend(fontsize=font_size_ticks,framealpha=1)
plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Error ($^\circ$C)',fontsize=font_size,labelpad = 15)
plt.savefig('plots/ridge_alpha.pdf',bbox_inches="tight")

fig = plt.figure(figsize = (13,9)) 
for ind_feature in range(d):
    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:
        plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[ind_feature,:],lw=3,color="silver")
plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[largest_coeff_ind,:],lw=3,color="black",label="Bowling Green")
plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[second_largest_coeff_ind,:],lw=3,ls="dashed",color="black",label="Bedford")
plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[third_largest_coeff_ind,:],lw=4,ls="dotted",color="black",label="Elkins")
plt.legend(fontsize=font_size_ticks,framealpha=1)
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
plt.xlim([alphas_val_ridge[0],alphas_val_ridge[-1]])
plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 20)
plt.savefig('plots/ridge_coeffs_reg_param.pdf',bbox_inches="tight")


n = 200
alphas_lasso_val = np.logspace(-4, 2.5, n_alphas)
lasso_training_error_alpha = np.zeros(n_alphas) 
lasso_test_error_alpha = np.zeros(n_alphas)
lasso_coeffs_array_alpha = np.zeros((d,n_alphas)) 

for ind_alpha,alpha_val in enumerate(alphas_lasso_val):
    XT_train_n = XT_train[:n,:]
    y_train_n = y_train[:n]
    
    lasso_model_alpha = Lasso(alpha=alpha_val,max_iter=100000).fit(XT_train_n, y_train_n)
    lasso_training_error_alpha[ind_alpha] = np.sqrt(np.sum((y_train_n - lasso_model_alpha.predict(XT_train_n))**2) / n )
    lasso_test_error_alpha[ind_alpha] = np.sqrt(np.sum((y_test - lasso_model_alpha.predict(XT_test))**2) / n_test )
    lasso_coeffs_array_alpha[:,ind_alpha] = lasso_model_alpha.coef_
    



fig = plt.figure(figsize = (9,9)) 
plt.semilogx(2*n*alphas_lasso_val,lasso_test_error_alpha,lw=4,color="black",label="Test error")
plt.semilogx(2*n*alphas_lasso_val,lasso_training_error_alpha,ls="dashed",lw=4,color="black",label="Training error")
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
plt.legend(fontsize=font_size-5,framealpha=1)
plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 20)
plt.ylabel(r'Error ($^\circ$C)',fontsize=font_size,labelpad = 15)
plt.savefig('plots/lasso_alpha.pdf',bbox_inches="tight")

plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)

fig = plt.figure(figsize = (13,9)) 
for ind_feature in range(d):
    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:
        plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[ind_feature,:],lw=3,color="silver")
plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[largest_coeff_ind,:],lw=3,color="black",label="Bowling Green")
plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[second_largest_coeff_ind,:],lw=3,ls="dashed",color="black",label="Bedford")
plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[third_largest_coeff_ind,:],lw=3,ls="dotted",color="black",label="Elkins")
plt.legend(fontsize=font_size-5,framealpha=1,loc="lower right")
plt.xticks(fontsize=font_size_ticks) 
plt.yticks(fontsize=font_size_ticks)
plt.xlim([2*n*alphas_lasso_val[0],2*n*alphas_lasso_val[-1]])
plt.ylim([-0.4,0.65])
plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 20)
plt.savefig('plots/lasso_coeffs_reg_param.pdf',bbox_inches="tight")









