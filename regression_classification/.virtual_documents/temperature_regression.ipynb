import matplotlib
import matplotlib.pyplot as plt
import numpy as np
from os import listdir
import seaborn as sns
from scipy import stats
from numpy import linalg as LA
from sklearn.linear_model import LinearRegression,Ridge,RidgeCV,Lasso,LassoCV
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor
from numpy.random import default_rng
from sklearn import tree

font_size = 30
font_size_ticks = 25

np.set_printoptions(precision=5)




def process_name(x):
    x = x[14:]
    x = x[:-7]
    x = x.translate(str.maketrans('','','_1234567890'))
    return x[2:] + ", " + x[:2]

def state(x):
    x = x[14:]
    return x[:2]

str_path = "../data/weather/"

file_name_temperatures_2015 = str_path + "temperatures_2015.npy"
file_name_temperatures_2016 = str_path + "temperatures_2016.npy"

data_matrix_2015 = np.load(file_name_temperatures_2015)
data_matrix_2016 = np.load(file_name_temperatures_2016)

file_name_list = listdir(str_path + "hourly/2015/")
file_name_list.sort()

latitudes = []
longitudes = []
for ind,name in enumerate(file_name_list):
    print(ind)
    print(name)
    if name[0] != '.':
        data_aux = np.loadtxt(str_path + "hourly/2015/" + name, usecols=range(14))
        print("longitude: " + str(data_aux[0,6]))
        print("latitude: " + str(data_aux[0,7]))
        longitudes.append(data_aux[0,6])
        latitudes.append(data_aux[0,7])


def remove_faulty_measurements(data,verbose):
    min_val = -100 # We assume temperatures cannot be lower than -100
    for ind in range(len(data)):
        median = np.median(data[data > min_val])
        if data[ind] < min_val:
            if verbose:
                print(str(ind) + ": " + str(data[ind]))
            aux_ind = ind-1
            while aux_ind > 0:
                if data[aux_ind] > min_val:
                    data[ind] = data[aux_ind]
                    if verbose:
                        print("changed entry " + str(aux_ind) + ": " + str(data[ind]))
                    break
                else:
                    ind -= 1
    return data

verbose = True
for ind in range(data_matrix_2015.shape[1]):
    print(ind)
    data_matrix_2015[:,ind] = remove_faulty_measurements(data_matrix_2015[:,ind],verbose)
    data_matrix_2016[:,ind] = remove_faulty_measurements(data_matrix_2016[:,ind],verbose)


print(data_matrix_2015.shape)
print(data_matrix_2016.shape)

ind_response = 55
print( "Response is " + process_name(str(file_name_list[ind_response])))
y_all = data_matrix_2015[:,ind_response]
y_2016 = data_matrix_2016[:,ind_response]
n_2016 = len(y_2016)
longitude_y = longitudes[ind_response]
latitude_y = latitudes[ind_response]

ind_X = np.hstack((np.arange(0,ind_response),np.arange(ind_response+1,data_matrix_2015.shape[1])))
XT_all = data_matrix_2015[:,ind_X]
XT_2016 = data_matrix_2016[:,ind_X]
longitudes_X = np.array(longitudes)[ind_X]
latitudes_X = np.array(latitudes)[ind_X]

d = XT_all.shape[1]

n_test = int(1e3)
n_data = data_matrix_2015.shape[0]
print(n_data)
rng = default_rng(2023)
aux_ind = rng.permutation(n_data)
ind_test = aux_ind[:n_test]
XT_test = XT_all[ind_test,:]
y_test = y_all[ind_test]
ind_train = aux_ind[n_test:]
XT_train = XT_all[ind_train,:]
y_train = y_all[ind_train]
print(ind_X[:5])
print(XT_train.shape)
print(y_train.shape)
n_train = XT_train.shape[0]
print("Number of features",d)
print("Number of training examples",n_train)


OLS_model = LinearRegression().fit(XT_train, y_train)
OLS_training_error = np.sqrt(np.sum((y_train - OLS_model.predict(XT_train))**2) / n_train )
#training_error = OLS_model.score(XT_train_n, y_train_n)
OLS_test_error = np.sqrt(np.sum((y_test - OLS_model.predict(XT_test))**2) / n_test )
#test_error = OLS_model.score(XT_test, y_test)
OLS_test_error_2016 = np.sqrt(np.sum((y_2016 - OLS_model.predict(XT_2016))**2) / n_2016 )

print("OLS training error",OLS_training_error)
print("OLS test error",OLS_test_error)
print("OLS test error 2016",OLS_test_error_2016)



tree_model = RandomForestRegressor(random_state=0,max_features=1).fit(XT_train, y_train)



n_trees_vals = [1,2,4,8,16,32,64,128,256]

for n_trees in n_trees_vals:
    RF_model = RandomForestRegressor(n_estimators = n_trees,min_samples_leaf=10,max_features=0.3, 
                                     random_state=0,max_depth = 10).fit(XT_train, y_train)
    RF_training_error = np.sqrt(np.sum((y_train - RF_model.predict(XT_train))**2) / n_train )
    RF_test_error = np.sqrt(np.sum((y_test - RF_model.predict(XT_test))**2) / n_test )
    RF_test_error_2016 = np.sqrt(np.sum((y_2016 - RF_model.predict(XT_2016))**2) / n_2016 )
    print("Number of trees",str(n_trees))
    print("Random forest training error",RF_training_error)
    print("Random forest test error",RF_test_error)
    print("Random forest test error 2016",RF_test_error_2016)



n_trees_vals = [1,2,4,8,16,32,64,128,256]

for n_trees in n_trees_vals:
    GB_model = GradientBoostingRegressor(n_estimators = n_trees,min_samples_leaf=10,
                                     random_state=0,max_depth = 5).fit(XT_train, y_train)
    GB_training_error = np.sqrt(np.sum((y_train - GB_model.predict(XT_train))**2) / n_train )
    GB_test_error = np.sqrt(np.sum((y_test - GB_model.predict(XT_test))**2) / n_test )
    GB_test_error_2016 = np.sqrt(np.sum((y_2016 - GB_model.predict(XT_2016))**2) / n_2016 )
    print("Number of trees",str(n_trees))
    print("Gradient boosting training error",GB_training_error)
    print("Gradient boosting test error",GB_test_error)
    print("Gradient boosting test error 2016",GB_test_error_2016)





