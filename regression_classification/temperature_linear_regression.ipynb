{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Material for the book [Probability and Statistics for Data Science](https://a.co/d/cAss9mO). A free preprint, videos, code, slides and solutions to exercises are available at https://www.ps4ds.net/\n",
    "\n",
    "Code for Examples 12.20, and Figures 12.10, 12.12, 12.13 and 12.17 \n",
    "\n",
    "Linear models of the temperature at Versailles (Kentucky) as a function of the temperature at 133 other weather stations. The models are trained and tested using hourly temperature data from 2015 and 2016\\\n",
    "Topics and relevant videos: [Linear regression, ordinary least squares](https://www.youtube.com/watch?v=Ktdh6qXeakA), [coefficient error](https://www.youtube.com/watch?v=YD607IJa4hs), [training error](https://www.youtube.com/watch?v=aizK3kUkAq8), [test error](https://www.youtube.com/watch?v=jcLNsocHEBk), [ridge regression](https://www.youtube.com/watch?v=uv8H6RiFhdE), [the lasso, sparse regression](https://www.youtube.com/watch?v=GyEYOAPvOks)\n",
    "\n",
    "Author: Carlos Fernandez-Granda\\\n",
    "Data source: https://www1.ncdc.noaa.gov/pub/data/uscrn/products/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from numpy import linalg as LA\n",
    "from sklearn.linear_model import LinearRegression,Ridge,RidgeCV,Lasso,LassoCV\n",
    "from numpy.random import default_rng\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeature\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "font_size = 15\n",
    "font_size_ticks = 15\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# file_name_temperature_2015 = \"../data/weather/temperatures_2015.npy\"\n",
    "# file_name_temperature_2016 = \"../data/weather/temperatures_2016.npy\"\n",
    "# file_name_longitudes = \"../data/weather/longitudes.npy\"\n",
    "# file_name_latitudes = \"../data/weather/latitudes.npy\"\n",
    "\n",
    "# data_matrix_2015 = np.load(file_name_temperature_2015)\n",
    "# data_matrix_2016 = np.load(file_name_temperature_2016)\n",
    "# longitudes = np.load(file_name_longitudes)\n",
    "# latitudes = np.load(file_name_latitudes)\n",
    "\n",
    "# file_name_list = np.load('../data/weather/weather_station_names.npy')\n",
    "\n",
    "# Raw GitHub URLs\n",
    "url_temperature_2015 = \"https://raw.githubusercontent.com/cfgranda/ps4ds/main/data/weather/temperatures_2015.npy\"\n",
    "url_temperature_2016 = \"https://raw.githubusercontent.com/cfgranda/ps4ds/main/data/weather/temperatures_2016.npy\"\n",
    "url_longitudes = \"https://raw.githubusercontent.com/cfgranda/ps4ds/main/data/weather/longitudes.npy\"\n",
    "url_latitudes = \"https://raw.githubusercontent.com/cfgranda/ps4ds/main/data/weather/latitudes.npy\"\n",
    "url_station_names = \"https://raw.githubusercontent.com/cfgranda/ps4ds/main/data/weather/weather_station_names.npy\"\n",
    "\n",
    "# Load .npy files using BytesIO\n",
    "with urllib.request.urlopen(url_temperature_2015) as response:\n",
    "    data_matrix_2015 = np.load(io.BytesIO(response.read()))\n",
    "\n",
    "with urllib.request.urlopen(url_temperature_2016) as response:\n",
    "    data_matrix_2016 = np.load(io.BytesIO(response.read()))\n",
    "\n",
    "with urllib.request.urlopen(url_longitudes) as response:\n",
    "    longitudes = np.load(io.BytesIO(response.read()))\n",
    "\n",
    "with urllib.request.urlopen(url_latitudes) as response:\n",
    "    latitudes = np.load(io.BytesIO(response.read()))\n",
    "\n",
    "with urllib.request.urlopen(url_station_names) as response:\n",
    "    file_name_list = np.load(io.BytesIO(response.read()))\n",
    "\n",
    "def process_name(x):\n",
    "    x = x[14:]\n",
    "    x = x[:-7]\n",
    "    x = x.translate(str.maketrans('','','_1234567890'))\n",
    "    return x[2:] + \", \" + x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 stations processed\n",
      "10 stations processed\n",
      "20 stations processed\n",
      "30 stations processed\n",
      "40 stations processed\n",
      "50 stations processed\n",
      "60 stations processed\n",
      "70 stations processed\n",
      "80 stations processed\n",
      "90 stations processed\n",
      "100 stations processed\n",
      "110 stations processed\n",
      "120 stations processed\n",
      "130 stations processed\n"
     ]
    }
   ],
   "source": [
    "def remove_faulty_measurements(data,verbose):\n",
    "    min_val = -100 # We assume temperatures cannot be lower than -100\n",
    "    for ind in range(len(data)):\n",
    "        if data[ind] < min_val:\n",
    "            if verbose:\n",
    "                print(str(ind) + \": \" + str(data[ind]))\n",
    "            aux_ind = ind-1\n",
    "            while aux_ind > 0:\n",
    "                if data[aux_ind] > min_val:\n",
    "                    data[ind] = data[aux_ind]\n",
    "                    if verbose:\n",
    "                        print(\"entry \" + str(aux_ind) + \" changed to \" + str(data[ind]))\n",
    "                    break\n",
    "                else:\n",
    "                    ind -= 1\n",
    "    return data\n",
    "\n",
    "verbose = False\n",
    "for ind in range(data_matrix_2015.shape[1]):\n",
    "    if np.mod(ind,10) == 0:\n",
    "        print(str(ind) + \" stations processed\")\n",
    "    data_matrix_2015[:,ind] = remove_faulty_measurements(data_matrix_2015[:,ind],verbose)\n",
    "    data_matrix_2016[:,ind] = remove_faulty_measurements(data_matrix_2016[:,ind],verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response is Versailles, KY\n",
      "Number of features 133\n",
      "Total number of training examples 7760\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test data\n",
    "ind_response = 55\n",
    "print( \"Response is \" + process_name(str(file_name_list[ind_response])))\n",
    "y_all = data_matrix_2015[:,ind_response]\n",
    "y_2016 = data_matrix_2016[:,ind_response]\n",
    "n_2016 = len(y_2016)\n",
    "longitude_y = longitudes[ind_response]\n",
    "latitude_y = latitudes[ind_response]\n",
    "\n",
    "ind_X = np.hstack((np.arange(0,ind_response),np.arange(ind_response+1,data_matrix_2015.shape[1])))\n",
    "XT_all = data_matrix_2015[:,ind_X]\n",
    "XT_2016 = data_matrix_2016[:,ind_X]\n",
    "longitudes_X = np.array(longitudes)[ind_X]\n",
    "latitudes_X = np.array(latitudes)[ind_X]\n",
    "\n",
    "d = XT_all.shape[1]\n",
    "\n",
    "n_test = int(1e3)\n",
    "n_data = data_matrix_2015.shape[0]\n",
    "rng = default_rng(2023)\n",
    "aux_ind = rng.permutation(n_data)\n",
    "ind_test = aux_ind[:n_test]\n",
    "XT_test = XT_all[ind_test,:]\n",
    "y_test = y_all[ind_test]\n",
    "ind_train = aux_ind[n_test:]\n",
    "XT_train = XT_all[ind_train,:]\n",
    "y_train = y_all[ind_train]\n",
    "n_train = XT_train.shape[0]\n",
    "print(\"Number of features\",d)\n",
    "print(\"Total number of training examples\",n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m ridge_test_error_2016[ind_n] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((y_2016 \u001b[38;5;241m-\u001b[39m ridge_model_n\u001b[38;5;241m.\u001b[39mpredict(XT_2016))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m n_2016 )\n\u001b[1;32m     44\u001b[0m ridge_alphas[ind_n] \u001b[38;5;241m=\u001b[39m ridge_model_n\u001b[38;5;241m.\u001b[39malpha_\n\u001b[0;32m---> 46\u001b[0m lasso_model_n \u001b[38;5;241m=\u001b[39m LassoCV(n_alphas\u001b[38;5;241m=\u001b[39mn_alpha_lasso,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(XT_train_n, y_train_n)\n\u001b[1;32m     47\u001b[0m lasso_coeffs_array[:,ind_n] \u001b[38;5;241m=\u001b[39m lasso_model_n\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m     48\u001b[0m lasso_training_error[ind_n] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((y_train_n \u001b[38;5;241m-\u001b[39m lasso_model_n\u001b[38;5;241m.\u001b[39mpredict(XT_train_n))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m n )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1795\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1790\u001b[0m     model\u001b[38;5;241m.\u001b[39mprecompute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;66;03m# MultiTaskElasticNetCV does not (yet) support sample_weight, even\u001b[39;00m\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# not sample_weight=None.\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1050\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath(\n\u001b[1;32m   1051\u001b[0m     X,\n\u001b[1;32m   1052\u001b[0m     y[:, k],\n\u001b[1;32m   1053\u001b[0m     l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[1;32m   1054\u001b[0m     eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1055\u001b[0m     n_alphas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1056\u001b[0m     alphas\u001b[38;5;241m=\u001b[39m[alpha],\n\u001b[1;32m   1057\u001b[0m     precompute\u001b[38;5;241m=\u001b[39mprecompute,\n\u001b[1;32m   1058\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mthis_Xy,\n\u001b[1;32m   1059\u001b[0m     copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1060\u001b[0m     coef_init\u001b[38;5;241m=\u001b[39mcoef_[k],\n\u001b[1;32m   1061\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1062\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1063\u001b[0m     positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive,\n\u001b[1;32m   1064\u001b[0m     check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;66;03m# from here on **params\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   1067\u001b[0m     X_offset\u001b[38;5;241m=\u001b[39mX_offset,\n\u001b[1;32m   1068\u001b[0m     X_scale\u001b[38;5;241m=\u001b[39mX_scale,\n\u001b[1;32m   1069\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1070\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m   1071\u001b[0m     selection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection,\n\u001b[1;32m   1072\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1073\u001b[0m )\n\u001b[1;32m   1074\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1075\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    664\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    665\u001b[0m         coef_,\n\u001b[1;32m    666\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m         positive,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent(\n\u001b[1;32m    679\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    685\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Computation of ordinary least squares, ridge regression and lasso estimators \n",
    "# for different number of training data\n",
    "n_vals = np.logspace(np.log10(d),np.log10(n_train)).astype(int)\n",
    "n_alphas = 200\n",
    "n_alpha_lasso = 200\n",
    "alphas_val = np.logspace(-1, 6, n_alphas)\n",
    "\n",
    "n_len = len(n_vals)\n",
    "cov_matrix_eigvals = np.zeros((d,n_len)) \n",
    "\n",
    "OLS_coeffs_array = np.zeros((d,n_len)) \n",
    "OLS_training_error = np.zeros(n_len)\n",
    "OLS_test_error = np.zeros(n_len)\n",
    "OLS_test_error_2016 = np.zeros(n_len)\n",
    "ridge_coeffs_array = np.zeros((d,n_len)) \n",
    "ridge_training_error = np.zeros(n_len)\n",
    "ridge_test_error = np.zeros(n_len)\n",
    "ridge_test_error_2016 = np.zeros(n_len)\n",
    "ridge_alphas = np.zeros(n_len) \n",
    "lasso_coeffs_array = np.zeros((d,n_len)) \n",
    "lasso_training_error = np.zeros(n_len)\n",
    "lasso_test_error = np.zeros(n_len)\n",
    "lasso_test_error_2016 = np.zeros(n_len)\n",
    "lasso_alphas = np.zeros(n_len) \n",
    "\n",
    "for ind_n,n in enumerate(n_vals):\n",
    "    XT_train_n = XT_train[:n,:]\n",
    "    y_train_n = y_train[:n]\n",
    "    cov_matrix = np.cov(XT_train_n.T,ddof=1)\n",
    "    eigvals_cov_matrix,eigvecs_cov_matrix = np.linalg.eig(cov_matrix)\n",
    "    cov_matrix_eigvals[:,ind_n] = np.sort(eigvals_cov_matrix)\n",
    "\n",
    "    OLS_model_n = LinearRegression().fit(XT_train_n, y_train_n)\n",
    "    OLS_coeffs_array[:,ind_n] = OLS_model_n.coef_\n",
    "    OLS_training_error[ind_n] = np.sqrt(np.sum((y_train_n - OLS_model_n.predict(XT_train_n))**2) / n )\n",
    "    OLS_test_error[ind_n] = np.sqrt(np.sum((y_test - OLS_model_n.predict(XT_test))**2) / n_test )\n",
    "    OLS_test_error_2016[ind_n] = np.sqrt(np.sum((y_2016 - OLS_model_n.predict(XT_2016))**2) / n_2016 )\n",
    "    \n",
    "    ridge_model_n = RidgeCV(alphas=alphas_val).fit(XT_train_n, y_train_n)\n",
    "    ridge_coeffs_array[:,ind_n] = ridge_model_n.coef_\n",
    "    ridge_training_error[ind_n] = np.sqrt(np.sum((y_train_n - ridge_model_n.predict(XT_train_n))**2) / n )\n",
    "    ridge_test_error[ind_n] = np.sqrt(np.sum((y_test - ridge_model_n.predict(XT_test))**2) / n_test )\n",
    "    ridge_test_error_2016[ind_n] = np.sqrt(np.sum((y_2016 - ridge_model_n.predict(XT_2016))**2) / n_2016 )\n",
    "    ridge_alphas[ind_n] = ridge_model_n.alpha_\n",
    "\n",
    "    lasso_model_n = LassoCV(n_alphas=n_alpha_lasso,max_iter=100000).fit(XT_train_n, y_train_n)\n",
    "    lasso_coeffs_array[:,ind_n] = lasso_model_n.coef_\n",
    "    lasso_training_error[ind_n] = np.sqrt(np.sum((y_train_n - lasso_model_n.predict(XT_train_n))**2) / n )\n",
    "    lasso_test_error[ind_n] = np.sqrt(np.sum((y_test - lasso_model_n.predict(XT_test))**2) / n_test )\n",
    "    lasso_test_error_2016[ind_n] = np.sqrt(np.sum((y_2016 - lasso_model_n.predict(XT_2016))**2) / n_2016 )\n",
    "    lasso_alphas[ind_n] = lasso_model_n.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between observed training and test error, and the theoretical analysis in the book\n",
    "markersize = 6\n",
    "xtick_vals = [133,250,500,1000,2000,5000]\n",
    "sigma_est = OLS_training_error[-1]\n",
    "theoretical_prediction_train = sigma_est * np.sqrt(1-d/n_vals)\n",
    "theoretical_prediction_test = sigma_est * np.sqrt(1+d/(n_vals-1))\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "plt.semilogx(n_vals,OLS_test_error,\"o\",markersize=markersize,markerfacecolor='black',markeredgecolor=\"black\",markeredgewidth =1,label=\"Test error\")\n",
    "plt.semilogx(n_vals,OLS_training_error,\"o\",markersize=markersize,markerfacecolor='white',markeredgecolor=\"black\",markeredgewidth =1.5,label=\"Training error\")\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.ylim([-0.15,4.25])\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.legend(fontsize=font_size,framealpha=1)\n",
    "plt.xlabel(r'Number of training data',fontsize=font_size,labelpad = 5)\n",
    "plt.ylabel(r'Error ($^\\circ$C)',fontsize=font_size,labelpad = 5)\n",
    "\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "plt.semilogx(n_vals,OLS_test_error,\"o\",markersize=markersize,markerfacecolor='silver',markeredgecolor=\"silver\",markeredgewidth =2)\n",
    "plt.semilogx(n_vals,OLS_training_error,\"o\",markersize=markersize,markerfacecolor='silver',markeredgecolor=\"silver\",markeredgewidth =2)\n",
    "plt.semilogx(n_vals,theoretical_prediction_test,lw=3,ls=\"solid\",color=\"black\",label=\"Theoretical test error\")\n",
    "plt.semilogx(n_vals,theoretical_prediction_train,lw=2,ls=\"dashed\",color=\"black\",label=\"Theoretical training error\")\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.ylim([-0.15,4.25])\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.legend(fontsize=font_size,framealpha=1)\n",
    "plt.xlabel(r'Number of training data',fontsize=font_size,labelpad = 5)\n",
    "plt.ylabel(r'Error ($^\\circ$C)',fontsize=font_size,labelpad = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9,5)) \n",
    "plt.semilogx(n_vals,OLS_test_error,\"o\",markersize=markersize,markerfacecolor='black',markeredgecolor=\"black\",markeredgewidth =1,label=\"OLS (test)\")\n",
    "plt.semilogx(n_vals,ridge_test_error,\"^\",markersize=markersize,markerfacecolor='black',markeredgecolor=\"black\",markeredgewidth =1,label=\"Ridge (test)\")\n",
    "plt.semilogx(n_vals,lasso_test_error,\"d\",markersize=markersize,markerfacecolor='black',markeredgecolor=\"black\",markeredgewidth =1,label=\"Lasso (test)\")\n",
    "plt.semilogx(n_vals,lasso_training_error,\"d\",markersize=markersize,markerfacecolor='white',markeredgecolor=\"black\",markeredgewidth =1,label=\"Lasso (training)\")\n",
    "plt.semilogx(n_vals,ridge_training_error,\"^\",markersize=markersize,markerfacecolor='white',markeredgecolor=\"black\",markeredgewidth =1,label=\"Ridge (training)\")\n",
    "plt.semilogx(n_vals,OLS_training_error,\"o\",markersize=markersize,markerfacecolor='white',markeredgecolor=\"black\",markeredgewidth =1,label=\"OLS (training)\")\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.ylim([-0.15,4.25])\n",
    "#plt.xlim([1,n_train+10])\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.legend(fontsize=font_size,framealpha=1)\n",
    "plt.xlabel(r'Number of training data',fontsize=font_size,labelpad = 5)\n",
    "plt.ylabel(r'Error ($^\\circ$C)',fontsize=font_size,labelpad = 5)\n",
    "\n",
    "fig = plt.figure(figsize = (5,4)) \n",
    "plt.plot(n_vals,ridge_alphas/n_vals,\"o\",markersize=markersize,markerfacecolor='white',markeredgecolor=\"black\",markeredgewidth =1)\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 5)\n",
    "plt.ylabel(r'Regularization parameter $\\lambda/n$',fontsize=font_size,labelpad = 5)\n",
    "plt.title(r'Ridge regression',fontsize=font_size,pad = 5)\n",
    "\n",
    "fig = plt.figure(figsize = (5,4)) \n",
    "plt.plot(n_vals,2*lasso_alphas,\"o\",markersize=markersize,markerfacecolor='white',markeredgecolor=\"black\",markeredgewidth =1)\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 5)\n",
    "plt.ylabel(r'Regularization parameter $\\lambda/n$',fontsize=font_size,labelpad = 5)\n",
    "plt.title(r'Lasso',fontsize=font_size,pad = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_coeff_ind = np.argsort(OLS_coeffs_array[:,-1])[-1] \n",
    "second_largest_coeff_ind = np.argsort(OLS_coeffs_array[:,-1])[-2] \n",
    "third_largest_coeff_ind = np.argsort(OLS_coeffs_array[:,-1])[-3] \n",
    "\n",
    "coeffs = OLS_coeffs_array[:,-1]\n",
    "coeff_marker = 40\n",
    "print(\"Largest coefficient:\",process_name(file_name_list[ind_X[largest_coeff_ind]] ))\n",
    "print(\"2nd largest coefficient:\",process_name(file_name_list[ind_X[second_largest_coeff_ind]]))\n",
    "print(\"3rd largest coefficient:\",process_name(file_name_list[ind_X[third_largest_coeff_ind]]))\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.LambertConformal())\n",
    "ax.set_extent([-120, -77.5, 24, 45], ccrs.Geodetic())\n",
    "\n",
    "ax.coastlines()\n",
    "ax.plot(longitude_y,latitude_y, '*', markersize=20,color=\"black\",markeredgewidth=2,\n",
    "        markerfacecolor=\"white\",transform=ccrs.Geodetic(),label='Response')\n",
    "for ind in range(d):\n",
    "    if coeffs[ind] > 0:\n",
    "        ax.plot(longitudes_X[ind],latitudes_X[ind],'o',ms=coeff_marker*coeffs[ind],color=\"black\",markeredgewidth=2,\n",
    "                 markerfacecolor=\"white\",transform=ccrs.Geodetic())\n",
    "    else:\n",
    "        ax.plot(longitudes_X[ind],latitudes_X[ind],'o',ms=-coeff_marker*coeffs[ind],markeredgecolor=\"black\",markeredgewidth=2,\n",
    "                 markerfacecolor=\"black\",transform=ccrs.Geodetic())\n",
    "plt.text(longitude_y+1,latitude_y-0.5,\"Versailles\",transform=ccrs.Geodetic(),fontsize=24)\n",
    "plt.text(longitude_y-13.5,latitude_y-1,\"Bowling Green\",transform=ccrs.Geodetic(),fontsize=24)\n",
    "plt.text(longitude_y-8.25,latitude_y+1.75,\"Bedford\",transform=ccrs.Geodetic(),fontsize=24)\n",
    "plt.text(longitude_y+3,latitude_y+2,\"Elkins\",transform=ccrs.Geodetic(),fontsize=24)\n",
    "plt.ylabel('Latitude',fontsize=font_size,labelpad=10)\n",
    "plt.xlabel('Longitude',fontsize=font_size,labelpad=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 2\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "for ind_feature in range(d):\n",
    "    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:\n",
    "        plt.semilogx(n_vals,OLS_coeffs_array[ind_feature,:],lw=linewidth,color=\"silver\")\n",
    "plt.semilogx(n_vals,OLS_coeffs_array[largest_coeff_ind,:],lw=linewidth,color=\"black\",label=\"Bowling Green\")\n",
    "plt.semilogx(n_vals,OLS_coeffs_array[second_largest_coeff_ind,:],lw=linewidth,ls=\"dashed\",color=\"black\",label=\"Bedford\")\n",
    "plt.semilogx(n_vals,OLS_coeffs_array[third_largest_coeff_ind,:],lw=linewidth+1,ls=\"dotted\",color=\"black\",label=\"Elkins\")\n",
    "plt.legend(fontsize=font_size,framealpha=1,loc=\"lower right\")\n",
    "plt.ylim([-1,1])\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 5)\n",
    "plt.title('Ordinary least squares',fontsize=font_size,pad = 5)\n",
    "\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "for ind_feature in range(d):\n",
    "    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:\n",
    "        plt.semilogx(n_vals,ridge_coeffs_array[ind_feature,:],lw=linewidth,color=\"silver\")\n",
    "plt.semilogx(n_vals,ridge_coeffs_array[largest_coeff_ind,:],lw=linewidth,color=\"black\",label=\"Bowling Green\")\n",
    "plt.semilogx(n_vals,ridge_coeffs_array[second_largest_coeff_ind,:],lw=linewidth,ls=\"dashed\",color=\"black\",label=\"Bedford\")\n",
    "plt.semilogx(n_vals,ridge_coeffs_array[third_largest_coeff_ind,:],lw=linewidth+1,ls=\"dotted\",color=\"black\",label=\"Elkins\")\n",
    "plt.legend(fontsize=font_size,framealpha=1,loc=\"lower right\")\n",
    "plt.ylim([-1,1])\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 5)\n",
    "plt.title('Ridge regression',fontsize=font_size,pad = 5)\n",
    "\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "for ind_feature in range(d):\n",
    "    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:\n",
    "        plt.semilogx(n_vals,lasso_coeffs_array[ind_feature,:],lw=linewidth,color=\"silver\")\n",
    "plt.semilogx(n_vals,lasso_coeffs_array[largest_coeff_ind,:],lw=linewidth,color=\"black\",label=\"Bowling Green\")\n",
    "plt.semilogx(n_vals,lasso_coeffs_array[second_largest_coeff_ind,:],lw=linewidth,ls=\"dashed\",color=\"black\",label=\"Bedford\")\n",
    "plt.semilogx(n_vals,lasso_coeffs_array[third_largest_coeff_ind,:],lw=linewidth+1,ls=\"dotted\",color=\"black\",label=\"Elkins\")\n",
    "plt.legend(fontsize=font_size,framealpha=1,loc=\"lower right\")\n",
    "plt.ylim([-1,1])\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 5)\n",
    "plt.title('Lasso',fontsize=font_size,pad = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,3)) \n",
    "plt.plot(n_vals,cov_matrix_eigvals[0,:],\"o\",markersize=markersize,markerfacecolor='white',markeredgecolor=\"black\",markeredgewidth =1)\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(xtick_vals)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel(r'Number of training data $n$',fontsize=font_size,labelpad = 5)\n",
    "plt.title(r'Smallest eigenvalue of design matrix',fontsize=font_size,pad = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "alphas_val_ridge = np.logspace(-1, 6, n_alphas)\n",
    "ridge_training_error_alpha = np.zeros(n_alphas) \n",
    "ridge_test_error_alpha = np.zeros(n_alphas)\n",
    "ridge_coeffs_array_alpha = np.zeros((d,n_alphas)) \n",
    "\n",
    "for ind_alpha,alpha_val in enumerate(alphas_val_ridge):\n",
    "    XT_train_n = XT_train[:n,:]\n",
    "    y_train_n = y_train[:n]\n",
    "    \n",
    "    ridge_model_alpha = Ridge(alpha=alpha_val).fit(XT_train_n, y_train_n)\n",
    "    ridge_training_error_alpha[ind_alpha] = np.sqrt(np.sum((y_train_n - ridge_model_alpha.predict(XT_train_n))**2) / n )\n",
    "    ridge_test_error_alpha[ind_alpha] = np.sqrt(np.sum((y_test - ridge_model_alpha.predict(XT_test))**2) / n_test )\n",
    "    ridge_coeffs_array_alpha[:,ind_alpha] = ridge_model_alpha.coef_\n",
    "\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "plt.semilogx(alphas_val,ridge_test_error_alpha,lw=4,color=\"black\",label=\"Test error\")\n",
    "plt.semilogx(alphas_val,ridge_training_error_alpha,ls=\"dashed\",lw=4,color=\"black\",label=\"Training error\")\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.legend(fontsize=font_size_ticks,framealpha=1)\n",
    "plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 5)\n",
    "plt.ylabel(r'Error ($^\\circ$C)',fontsize=font_size,labelpad = 5)\n",
    "plt.title('Ridge regression, n = '+str(n),fontsize=font_size,pad = 5);\n",
    "\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "for ind_feature in range(d):\n",
    "    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:\n",
    "        plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[ind_feature,:],lw=2,color=\"silver\")\n",
    "plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[largest_coeff_ind,:],lw=3,color=\"black\",label=\"Bowling Green\")\n",
    "plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[second_largest_coeff_ind,:],lw=3,ls=\"dashed\",color=\"black\",label=\"Bedford\")\n",
    "plt.semilogx(alphas_val_ridge,ridge_coeffs_array_alpha[third_largest_coeff_ind,:],lw=4,ls=\"dotted\",color=\"black\",label=\"Elkins\")\n",
    "plt.legend(fontsize=font_size_ticks,framealpha=1)\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.xlim([alphas_val_ridge[0],alphas_val_ridge[-1]])\n",
    "plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 5)\n",
    "plt.title('Ridge regression, n = '+str(n),fontsize=font_size,pad = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "alphas_lasso_val = np.logspace(-4, 2.5, n_alphas)\n",
    "lasso_training_error_alpha = np.zeros(n_alphas) \n",
    "lasso_test_error_alpha = np.zeros(n_alphas)\n",
    "lasso_coeffs_array_alpha = np.zeros((d,n_alphas)) \n",
    "\n",
    "for ind_alpha,alpha_val in enumerate(alphas_lasso_val):\n",
    "    XT_train_n = XT_train[:n,:]\n",
    "    y_train_n = y_train[:n]\n",
    "    \n",
    "    lasso_model_alpha = Lasso(alpha=alpha_val,max_iter=100000).fit(XT_train_n, y_train_n) # max_iter=100000\n",
    "    lasso_training_error_alpha[ind_alpha] = np.sqrt(np.sum((y_train_n - lasso_model_alpha.predict(XT_train_n))**2) / n )\n",
    "    lasso_test_error_alpha[ind_alpha] = np.sqrt(np.sum((y_test - lasso_model_alpha.predict(XT_test))**2) / n_test )\n",
    "    lasso_coeffs_array_alpha[:,ind_alpha] = lasso_model_alpha.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9,4)) \n",
    "plt.semilogx(2*n*alphas_lasso_val,lasso_test_error_alpha,lw=4,color=\"black\",label=\"Test error\")\n",
    "plt.semilogx(2*n*alphas_lasso_val,lasso_training_error_alpha,ls=\"dashed\",lw=4,color=\"black\",label=\"Training error\")\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.legend(fontsize=font_size,framealpha=1)\n",
    "plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 5)\n",
    "plt.ylabel(r'Error ($^\\circ$C)',fontsize=font_size,labelpad = 5)\n",
    "plt.title('Lasso, n = '+str(n),fontsize=font_size,pad = 5);\n",
    "\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "\n",
    "fig = plt.figure(figsize = (9,4)) \n",
    "for ind_feature in range(d):\n",
    "    if ind_feature != largest_coeff_ind and ind_feature != second_largest_coeff_ind and ind_feature != third_largest_coeff_ind:\n",
    "        plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[ind_feature,:],lw=2,color=\"silver\")\n",
    "plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[largest_coeff_ind,:],lw=3,color=\"black\",label=\"Bowling Green\")\n",
    "plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[second_largest_coeff_ind,:],lw=3,ls=\"dashed\",color=\"black\",label=\"Bedford\")\n",
    "plt.semilogx(2*n*alphas_lasso_val,lasso_coeffs_array_alpha[third_largest_coeff_ind,:],lw=3,ls=\"dotted\",color=\"black\",label=\"Elkins\")\n",
    "plt.legend(fontsize=font_size,framealpha=1,loc=\"lower right\")\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.xlim([2*n*alphas_lasso_val[0],2*n*alphas_lasso_val[-1]])\n",
    "plt.ylim([-0.4,0.65])\n",
    "plt.xlabel(r'Regularization parameter',fontsize=font_size,labelpad = 5)\n",
    "plt.title('Lasso, n = '+str(n),fontsize=font_size,pad = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
