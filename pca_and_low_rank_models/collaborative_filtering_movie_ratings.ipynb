{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fdc1a1-195d-46f8-9134-9a86a0043b16",
   "metadata": {},
   "source": [
    "Material for the book [Probability and Statistics for Data Science](https://a.co/d/cAss9mO). A free preprint, videos, code, slides and solutions to exercises are available at https://www.ps4ds.net/\n",
    "\n",
    "Code for Example 11.44\n",
    "\n",
    "Analysis of a dataset consisting of real movie ratings, our goal is to estimate missing ratings\\\n",
    "Topics and relevant videos: [Low rank model, singular value decomposition](https://www.youtube.com/watch?v=cLJ3tfgYanM), [matrix completion, collaborative filtering, singular-value thresholding, imputation](https://www.youtube.com/watch?v=yXPlhx4xWRQ) \n",
    "\n",
    "Author: Carlos Fernandez-Granda\\\n",
    "Data source: https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896f3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(2022)\n",
    "\n",
    "font_size = 15\n",
    "font_size_ticks = 15\n",
    "\n",
    "rating_names = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "movie_names = ['movie_id', 'title', 'release_date']\n",
    "\n",
    "# ratings = pd.read_csv('../data/ml-100k/u.data', sep='\\t', encoding='latin-1',names=rating_names)\n",
    "# movies = pd.read_csv('../data/ml-100k/u.item', sep='|', names=movie_names,usecols=range(3),encoding='latin-1')\n",
    "\n",
    "# Raw GitHub URLs\n",
    "url_ratings = \"https://raw.githubusercontent.com/cfgranda/ps4ds/main/data/ml-100k/u.data\"\n",
    "url_movies = \"https://raw.githubusercontent.com/cfgranda/ps4ds/main/data/ml-100k/u.item\"\n",
    "\n",
    "# Load datasets\n",
    "ratings = pd.read_csv(url_ratings, sep='\\t', encoding='latin-1', names=rating_names)\n",
    "movies = pd.read_csv(url_movies, sep='|', encoding='latin-1', names=movie_names, usecols=range(3))\n",
    "\n",
    "data = pd.merge(movies,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3f38c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30055 observed ratings out of 100000\n"
     ]
    }
   ],
   "source": [
    "# We select the 100 movies and 1000 users with more ratings\n",
    "n_movies = 100\n",
    "n_users = 1000\n",
    "movies = data.title.value_counts()[:n_movies].index.tolist()\n",
    "users = np.array(data.user_id.value_counts()[:n_users].index.tolist())\n",
    "\n",
    "n_ratings = 0\n",
    "for ind,movie in enumerate(movies):\n",
    "    ratings = data[data[\"title\"] == movie]\n",
    "    for index, row in ratings.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        if user_id in users:\n",
    "            # print(movie + \" user: \" + str(user_id) + \" rating: \" + str(row['rating']))\n",
    "            n_ratings += 1\n",
    "print(str(n_ratings) + \" observed ratings out of \" + str(n_movies*n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79660058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a training, validation and test set using the observed ratings\n",
    "n_test = 1000\n",
    "n_val = 1000\n",
    "n_train = n_ratings - n_test - n_val\n",
    "full_rating_matrix = np.zeros((n_movies,n_users))\n",
    "for ind,movie in enumerate(movies):\n",
    "    ratings = data[data[\"title\"] == movie]\n",
    "    for index, row in ratings.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        if user_id in users:\n",
    "            full_rating_matrix[ind,np.where(users == user_id)]= row['rating']\n",
    "nonmissing_indices = np.flatnonzero(full_rating_matrix > 0.1)\n",
    "aux_ind = nonmissing_indices[np.random.permutation(np.arange(len(nonmissing_indices)))]\n",
    "test_ind = aux_ind[:n_test]\n",
    "val_ind = aux_ind[n_test:(n_test+n_val)]\n",
    "train_ind = aux_ind[(n_test+n_val):(n_test+n_val+n_train)]\n",
    "\n",
    "train_ratings = full_rating_matrix.flat[train_ind]        \n",
    "val_ratings = full_rating_matrix.flat[val_ind]\n",
    "test_ratings = full_rating_matrix.flat[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9586a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix_ini = np.zeros(full_rating_matrix.shape)\n",
    "rating_matrix_ini.flat[train_ind] = train_ratings\n",
    "mean_rating_movie = np.zeros(n_movies)\n",
    "\n",
    "# Impute mean rating of each movie to fill missing ratings, this works better than imputing the overall mean or the mean rating of the user\n",
    "for ind_movie in range(rating_matrix_ini.shape[0]):\n",
    "    nonzero_ind = np.nonzero(rating_matrix_ini[ind_movie,:])\n",
    "    mean_movie = np.mean(rating_matrix_ini[ind_movie,nonzero_ind])\n",
    "    mean_rating_movie[ind_movie] = mean_movie\n",
    "    rating_matrix_ini[ind_movie,rating_matrix_ini[ind_movie,:]==0] = mean_movie    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0ddc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Error: 0.653\n",
      "Iteration 1 Error: 0.584\n",
      "Iteration 2 Error: 0.546\n",
      "Iteration 3 Error: 0.522\n",
      "Iteration 4 Error: 0.505\n"
     ]
    }
   ],
   "source": [
    "# We obtain a low-rank model by truncating the singular-value decomposition of the estimated centered rating matrix  \n",
    "# The estimate is improved iteratively by reimputing the low-rank estimates corresponding to missing entries into the original matrix\n",
    "# and repeating the procedure\n",
    "def fit_low_rank_model(rank,rating_matrix_ini,train_ind,train_data,n_iter,convergence_thresh,verbose):\n",
    "    mean_train = np.mean(rating_matrix_ini)\n",
    "    centered_data = train_data - mean_train # We center by subtracting the sample mean of the training-set ratings\n",
    "    low_rank_estimate = rating_matrix_ini - mean_train\n",
    "    previous_fitting_error = 100\n",
    "    for ind in range(n_iter):\n",
    "        low_rank_estimate.flat[train_ind] = centered_data\n",
    "        u, s, vT = np.linalg.svd(low_rank_estimate, full_matrices=True)\n",
    "        low_rank_estimate = u[:,:rank] @ np.diag(s[:rank]) @ vT[:rank,:]\n",
    "        fitting_error = np.linalg.norm(centered_data-low_rank_estimate.flat[train_ind]) / np.sqrt(n_train)\n",
    "        if verbose:\n",
    "            print(\"Iteration \" + str(ind) + \" Error: \" + str(round(fitting_error,3)))\n",
    "        if np.abs(fitting_error-previous_fitting_error)/previous_fitting_error < convergence_thresh:\n",
    "            print(\"Converged after \" + str(ind) + \" iterations\")\n",
    "            break\n",
    "        else:\n",
    "            previous_fitting_error = fitting_error\n",
    "    return low_rank_estimate + mean_train\n",
    "\n",
    "n_iter = 5\n",
    "convergence_thresh = 1e-4\n",
    "verbose = True\n",
    "rank = 20\n",
    "estimate =fit_low_rank_model(rank,rating_matrix_ini,train_ind,train_ratings,n_iter,convergence_thresh,verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1\n",
      "Converged after 16 iterations\n",
      "Rank 2\n",
      "Converged after 27 iterations\n",
      "Rank 3\n",
      "Converged after 35 iterations\n",
      "Rank 4\n",
      "Converged after 44 iterations\n",
      "Rank 5\n",
      "Converged after 54 iterations\n",
      "Rank 6\n",
      "Converged after 64 iterations\n",
      "Rank 7\n"
     ]
    }
   ],
   "source": [
    "# We select the rank based on the validation error\n",
    "ranks = np.arange(1,10,1)\n",
    "train_error = np.zeros(len(ranks))\n",
    "val_error = np.zeros(len(ranks))\n",
    "\n",
    "n_iter = 500\n",
    "convergence_thresh = 1e-4\n",
    "verbose = False\n",
    "\n",
    "for ind,rank in enumerate(ranks):\n",
    "    print(\"Rank \" + str(rank))\n",
    "    estimate = fit_low_rank_model(rank,rating_matrix_ini,train_ind,train_ratings,n_iter,convergence_thresh,verbose)\n",
    "    train_error[ind] = np.linalg.norm(train_ratings-estimate.flat[train_ind]) / np.sqrt(n_train)\n",
    "    val_error[ind] = np.linalg.norm(val_ratings-estimate.flat[val_ind]) / np.sqrt(n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b70089",
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 7\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(ranks,train_error,linestyle=\"None\",marker='o',ms=markersize,color=\"black\",markeredgewidth=2,\n",
    "                     markerfacecolor=\"black\",label=\"Training error\")\n",
    "plt.plot(ranks,val_error,linestyle=\"None\",marker='o',ms=markersize,color=\"black\",markeredgewidth=2,\n",
    "                     markerfacecolor=\"white\",label=\"Validation error\")\n",
    "plt.ylabel('Root mean squared error',fontsize=font_size,labelpad=10)\n",
    "plt.xlabel('Rank',fontsize=font_size,labelpad=10)\n",
    "plt.xticks(fontsize=font_size_ticks) \n",
    "plt.yticks(fontsize=font_size_ticks)\n",
    "plt.legend(fontsize=font_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c571210",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rank = 3\n",
    "estimate = fit_low_rank_model(best_rank,rating_matrix_ini,train_ind,train_ratings,n_iter,convergence_thresh,verbose)\n",
    "test_error = np.linalg.norm(test_ratings-estimate.flat[test_ind]) / np.sqrt(n_test)\n",
    "print(\"Error of low-rank estimate: \" + str(np.round(test_error,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple, but effective, baseline: mean rating of each movie in the training set\n",
    "mean_rating_estimate = np.tile(np.array([mean_rating_movie]).T,(1,n_users))\n",
    "error_mean_rating = np.linalg.norm(test_ratings-mean_rating_estimate.flat[test_ind]) / np.sqrt(n_test)\n",
    "print(\"Error of mean-movie estimate: \" + str(np.round(error_mean_rating,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f370b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the singular vectors of the low-rank model reveals some of the structure learned by the model\n",
    "centered_estimate = estimate - np.mean(estimate)\n",
    "u, s, vT = np.linalg.svd(centered_estimate, full_matrices=True)\n",
    "factor_1 = u[:,0]\n",
    "factor_2 = u[:,1]\n",
    "factor_3 = u[:,2]\n",
    "\n",
    "k=4\n",
    "print(\"Factor 1\")\n",
    "sort_1 = np.argsort(factor_1)\n",
    "print(\"\\nMost negative\")\n",
    "for ind in range(k):\n",
    "    print(movies[sort_1[ind]] + \" \" + str(np.round(factor_1[sort_1[ind]],3)))\n",
    "print(\"\\nMost positive\")\n",
    "for ind in range(1,k+1):\n",
    "    print(movies[sort_1[-ind]] + \" \" + str(np.round(factor_1[sort_1[-ind]],3)))\n",
    "\n",
    "print(\"\\nFactor 2\")\n",
    "sort_2 = np.argsort(factor_2)\n",
    "print(\"\\nMost negative\")\n",
    "for ind in range(k):\n",
    "    print(movies[sort_2[ind]] + \" \" + str(np.round(factor_2[sort_2[ind]],3)))\n",
    "print(\"\\nMost positive\")\n",
    "for ind in range(1,k+1):\n",
    "    print(movies[sort_2[-ind]] + \" \" + str(np.round(factor_2[sort_2[-ind]],3)))\n",
    "\n",
    "print(\"\\nFactor 3\")\n",
    "sort_3 = np.argsort(factor_3)\n",
    "print(\"\\nMost negative\")\n",
    "for ind in range(k):\n",
    "    print(movies[sort_3[ind]] + \" \" + str(np.round(factor_3[sort_3[ind]],3)))\n",
    "print(\"\\nMost positive\")\n",
    "for ind in range(1,k+1):\n",
    "    print(movies[sort_3[-ind]] + \" \" + str(np.round(factor_3[sort_3[-ind]],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334bd38-3e23-4024-86ca-afe2119ea862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
